---
layout: post
title: CodeCarbon and our Responsibility as a Researcher
author: christopher
---


I played around with the new [CodeCarbon](https://codecarbon.io/) üí® package integrated into [Comet](https://www.comet.ml/) ‚òÑÔ∏è using [Huggingface](https://huggingface.co/) ü§ó to show a fine-tuned language model's carbon footprint.

In 2019 the paper "Energy and Policy Considerations for Deep Learning in NLP" [(Strubell/ Ganesh/ McCallum 2019)](https://arxiv.org/abs/1906.02243) popped up, discussing machine learning models' carbon footprint. Giving this as a portion of food for thought, the community starts thinking about the long-term effects and consequences.

The CodeCarbon üí® project is a software package to track the carbon footprint. This package is already integrated into Comet ‚òÑÔ∏è, a tool to analyze and track your models.

To exemplify the use of CodeCarbon üí®, I used a part of code from [this](https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb#scrollTo=uNx5pyRlIrJh) and HuggingFace' notebook to define a simple task for fine-tuning a language model (if you want, you can try out any other task).

Happy responsible researching!